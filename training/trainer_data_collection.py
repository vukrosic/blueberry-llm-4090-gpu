import torch
import torch.nn as nn
import torch.nn.functional as F
import math
import time
import matplotlib.pyplot as plt
from torch.utils.data import DataLoader
from torch.amp import autocast, GradScaler
from tqdm import tqdm
from configs.moe_config import MoEModelConfig
from models.moe_llm import MoEMinimalLLM
from optimizers.muon import Muon
from training.evaluation import evaluate_model
from utils.helpers import set_seed


def setup_muon_optimizer(model: nn.Module, config: MoEModelConfig):
    """Setup Muon optimizer with hybrid approach"""
    muon_params = []
    adamw_params = []

    for name, param in model.named_parameters():
        if (param.ndim == 2 and 
            'token_embedding' not in name and 
            'norm' not in name and 
            param.requires_grad):
            muon_params.append(param)
        else:
            adamw_params.append(param)

    print(f"  Muon parameters: {sum(p.numel() for p in muon_params):,}")
    print(f"  AdamW parameters: {sum(p.numel() for p in adamw_params):,}")

    # Use custom momentum if specified, otherwise default to 0.95
    momentum = getattr(config, 'momentum', 0.95)
    adamw_ratio = getattr(config, 'adamw_ratio', 0.1)
    
    muon_optimizer = Muon(muon_params, lr=config.muon_lr, momentum=momentum)
    adamw_optimizer = torch.optim.AdamW(adamw_params, lr=config.muon_lr*adamw_ratio, weight_decay=config.weight_decay)

    return [muon_optimizer, adamw_optimizer]


def train_moe_model(config: MoEModelConfig, train_loader: DataLoader, val_loader: DataLoader):
    """Train the MoE model"""
    print(f"\nðŸš€ Training MoE model with {config.num_experts} experts (top-{config.expert_top_k})")

    # Initialize model
    set_seed(42)
    model = MoEMinimalLLM(config)
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = model.to(device)

    # Count parameters
    total_params = sum(p.numel() for p in model.parameters())
    active_params = sum(p.numel() for n, p in model.named_parameters()
                       if 'expert' not in n)
    expert_params = total_params - active_params

    print(f"  ðŸ“Š Total parameters: {total_params:,}")
    print(f"  ðŸ“Š Active parameters: {active_params:,}")
    print(f"  ðŸ“Š Expert parameters: {expert_params:,}")
    print(f"  ðŸ“Š Parameter efficiency: {active_params/total_params:.1%} active per forward pass")

    # Setup optimizers
    optimizers = setup_muon_optimizer(model, config)

    # Learning rate schedule
    schedulers = []
    for optimizer in optimizers:
        warmup_steps = config.max_steps // 20
        def lr_lambda(step):
            if step < warmup_steps:
                return step / warmup_steps
            else:
                progress = (step - warmup_steps) / (config.max_steps - warmup_steps)
                return 0.1 + 0.9 * 0.5 * (1 + math.cos(math.pi * progress))

        scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)
        schedulers.append(scheduler)

    scaler = GradScaler() if config.use_amp else None

    # Training loop
    model.train()
    step = 0
    pbar = tqdm(total=config.max_steps, desc="Training MoE")
    
    # Track evaluation metrics over time
    eval_steps = []
    eval_losses = []
    eval_times = []

    while step < config.max_steps:
        for batch_idx, (x, y) in enumerate(train_loader):
            if step >= config.max_steps:
                break

            x, y = x.to(device), y.to(device)

            # Forward pass
            if config.use_amp:
                with autocast('cuda', dtype=torch.float16):
                    logits, aux_loss = model(x, return_aux_loss=True)
                    ce_loss = F.cross_entropy(logits.view(-1, config.vocab_size), y.view(-1))

                    # Combine main loss and auxiliary loss
                    total_loss = ce_loss
                    if aux_loss is not None:
                        total_loss = total_loss + aux_loss

                    loss = total_loss / config.gradient_accumulation_steps
                scaler.scale(loss).backward()
            else:
                logits, aux_loss = model(x, return_aux_loss=True)
                ce_loss = F.cross_entropy(logits.view(-1, config.vocab_size), y.view(-1))

                total_loss = ce_loss
                if aux_loss is not None:
                    total_loss = total_loss + aux_loss

                loss = total_loss / config.gradient_accumulation_steps
                loss.backward()

            # Optimizer step
            if (step + 1) % config.gradient_accumulation_steps == 0:
                if config.use_amp:
                    for optimizer in optimizers:
                        scaler.unscale_(optimizer)
                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)

                    for optimizer in optimizers:
                        scaler.step(optimizer)
                        optimizer.zero_grad()
                    for scheduler in schedulers:
                        scheduler.step()
                    scaler.update()
                else:
                    torch.nn.utils.clip_grad_norm_(model.parameters(), config.grad_clip)
                    for optimizer in optimizers:
                        optimizer.step()
                        optimizer.zero_grad()
                    for scheduler in schedulers:
                        scheduler.step()

            # Logging
            if step % 100 == 0:
                with torch.no_grad():
                    predictions = logits.argmax(dim=-1)
                    accuracy = (predictions == y).float().mean().item()
                    current_loss = ce_loss.item()
                    perplexity = math.exp(min(current_loss, 20))

                pbar.set_postfix({
                    'loss': f'{current_loss:.4f}',
                    'aux': f'{aux_loss.item() if aux_loss is not None else 0:.4f}',
                    'acc': f'{accuracy:.3f}',
                    'ppl': f'{perplexity:.1f}'
                })

            # Evaluation
            if step % config.eval_every == 0 and step > 0:
                eval_start_time = time.time()
                eval_metrics = evaluate_model(model, val_loader, config)
                eval_time = time.time() - eval_start_time
                
                # Track evaluation metrics
                eval_steps.append(step)
                eval_losses.append(eval_metrics['val_loss'])
                eval_times.append(time.time())
                
                print(f"\nStep {step}: Val Loss: {eval_metrics['val_loss']:.4f}, "
                      f"Val Acc: {eval_metrics['val_accuracy']:.4f}, "
                      f"Val PPL: {eval_metrics['val_perplexity']:.2f}")

            # Milestone evaluations
            if step in getattr(config, 'log_milestones', ()):    
                eval_metrics = evaluate_model(model, val_loader, config)
                print(f"\nðŸ§ª Milestone {step}: Val Loss: {eval_metrics['val_loss']:.4f}")

            step += 1
            if step % 20 == 0:
                pbar.update(20)

    pbar.close()

    # Final evaluation
    final_eval = evaluate_model(model, val_loader, config)
    
    # Add final evaluation to tracking
    eval_steps.append(config.max_steps)
    eval_losses.append(final_eval['val_loss'])
    eval_times.append(time.time())
    
    print(f"\nðŸ“Š Final Results:")
    print(f"   Val Loss: {final_eval['val_loss']:.4f}")
    print(f"   Val Accuracy: {final_eval['val_accuracy']:.4f}")
    print(f"   Val Perplexity: {final_eval['val_perplexity']:.2f}")
    
    # Plot evaluation loss over time
    if len(eval_times) > 1:
        # Convert timestamps to elapsed time in minutes
        start_time = eval_times[0]
        elapsed_times = [(t - start_time) / 60 for t in eval_times]
        
        plt.figure(figsize=(10, 6))
        plt.plot(elapsed_times, eval_losses, 'b-o', linewidth=2, markersize=6)
        plt.xlabel('Time (minutes)')
        plt.ylabel('Validation Loss')
        plt.title('Validation Loss vs Time')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('eval_loss_vs_time.png', dpi=300, bbox_inches='tight')
        plt.show()
        print(f"\nðŸ“ˆ Evaluation loss plot saved as 'eval_loss_vs_time.png'")

    # Save evaluation data for plotting
    eval_data = {
        'eval_steps': eval_steps,
        'eval_losses': eval_losses,
        'eval_times': eval_times,
        'config_lr': config.muon_lr
    }
    
    # Save to file for later plotting
    import pickle
    eval_file = f"temp_eval_data_lr_{config.muon_lr:.4f}.pkl"
    with open(eval_file, 'wb') as f:
        pickle.dump(eval_data, f)
    
    # Save evaluation data for plotting
    eval_data = {
        'eval_steps': eval_steps,
        'eval_losses': eval_losses,
        'eval_times': eval_times,
        'config_lr': config.muon_lr
    }
    
    # Save to file for later plotting
    import pickle
    eval_file = f"temp_eval_data_lr_{config.muon_lr:.4f}.pkl"
    with open(eval_file, 'wb') as f:
        pickle.dump(eval_data, f)
    
    return model, final_eval
